# Copyright 2025 DataRobot, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
This configuration option is available as the most flexible option with the most
production controls. It uses our LLM Blueprint and LLM Gateway options to enable
multiple LLMs through a single deployment with all of the DataRobot governance
and monitoring baked in.
"""

import datarobot as dr
import pulumi
import pulumi_datarobot as datarobot

from datarobot_pulumi_utils.pulumi import export
from datarobot_pulumi_utils.pulumi.stack import PROJECT_NAME
from datarobot_pulumi_utils.pulumi.custom_model_deployment import (
    CustomModelDeployment,
    DeploymentArgs,
    RegisteredModelArgs,
)
from datarobot_pulumi_utils.schema.custom_models import CustomModelArgs
from datarobot_pulumi_utils.schema.llms import (
    LLMSettings,
    LLMBlueprintArgs,
)
from datarobot_pulumi_utils.schema.exec_envs import RuntimeEnvironments

from . import use_case
from .lib{{ llm_app_name|lower|replace('-','_')}} import (
    validate_feature_flags,
    verify_llm,
    verify_llm_gateway_model_availability,
)

__all__ = [
    "custom_model_runtime_parameters",
    "app_runtime_parameters",
    "default_model",
    "{{llm_app_name}}_application_name",
    "{{llm_app_name}}_resource_name",
]

REQUIRED_FEATURE_FLAGS = {
    "ENABLE_LLM_GATEWAY": True,
    "ENABLE_MLOPS": True,
    "ENABLE_CUSTOM_INFERENCE_MODEL": True,
    "ENABLE_PUBLIC_NETWORK_ACCESS_FOR_ALL_CUSTOM_MODELS": True,
    "ENABLE_MLOPS_TEXT_GENERATION_TARGET_TYPE": True,
}

__all__ = [
    "{{llm_app_name}}_application_name",
    "{{llm_app_name}}_resource_name",
]

{{llm_app_name}}_application_name: str = "{{llm_app_name}}"
{{llm_app_name}}_resource_name: str = "[{{llm_app_name}}]"
# This is the model_id that the DataRobot LLM Gateway expects.
# You can get a list of these models by running:
"""
import datarobot
dr_client = datarobot.Client()
response = dr_client.get("genai/llmgw/catalog/")
data = response.json()
print("\n.   - ".join(
    [
        model["model"]
        for model in data["data"]
        if not model["isDeprecated"] and model["isActive"]
    ]
))
"""
default_model: str = "azure/gpt-4o-2024-11-20"

# Verify everything is configured properly for this configuration option.
validate_feature_flags(REQUIRED_FEATURE_FLAGS)

# This does a quick check that validates the selected model is available
# by checking the LLM Gateway. If it isn't, it will raise an error
# with the list of models that are available and not deprecated.
verify_llm_gateway_model_availability(default_model)

# LiteLLM support DataRobot as a provider, so this validates
# everything is working and the default LLM you've chosen is available
# by adding `datarobot/` in front of the model
verify_llm(f"datarobot/{default_model}")

playground = datarobot.Playground(
    use_case_id=use_case.id,
    resource_name="LLM Playground " + {{llm_app_name}}_resource_name,
)

llm_blueprint_args = LLMBlueprintArgs(
    resource_name="LLM Blueprint " + {{llm_app_name}}_resource_name,
    llm_id=default_model,
    llm_settings=LLMSettings(
        max_completion_length=2048,
        temperature=0.1,
        top_p=None,
    ),
)

llm_blueprint = datarobot.LlmBlueprint(
    playground_id=playground.id,
    **llm_blueprint_args.model_dump(),
)

custom_model_args = CustomModelArgs(
    resource_name="LLM Custom Model " + {{llm_app_name}}_resource_name,
    name="LLM Custom Model " + {{llm_app_name}}_resource_name,
    target_name="resultText",
    target_type=dr.enums.TARGET_TYPE.TEXT_GENERATION,
    replicas=1,
    base_environment_id=RuntimeEnvironments.PYTHON_312_MODERATIONS.value.id,
)

llm_custom_model = datarobot.CustomModel(
    **custom_model_args.model_dump(exclude_none=True),
    use_case_ids=[use_case.id],
    source_llm_blueprint_id=llm_blueprint.id,
)

registered_model_args = RegisteredModelArgs(
    resource_name="LLM Registered Model " + {{llm_app_name}}_resource_name,
)

prediction_environment = datarobot.PredictionEnvironment(
    resource_name="LLM Prediction Environment " + {{llm_app_name}}_resource_name,
    platform=dr.enums.PredictionEnvironmentPlatform.DATAROBOT_SERVERLESS,
)

deployment_args = DeploymentArgs(
    resource_name="LLM Deployment Args " + {{llm_app_name}}_resource_name,
    label=f"LLM Deployment [{PROJECT_NAME}] " + {{llm_app_name}}_resource_name,
    association_id_settings=datarobot.DeploymentAssociationIdSettingsArgs(
        column_names=["association_id"],
        auto_generate_id=False,
        required_in_prediction_requests=True,
    ),
    predictions_data_collection_settings=datarobot.DeploymentPredictionsDataCollectionSettingsArgs(
        enabled=True,
    ),
    predictions_settings=(
        datarobot.DeploymentPredictionsSettingsArgs(min_computes=0, max_computes=2)
    ),
)

llm_deployment = CustomModelDeployment(
    resource_name="LLM Blueprint Deployment " + {{llm_app_name}}_resource_name,
    use_case_ids=[use_case.id],
    custom_model_version_id=llm_custom_model.version_id,
    registered_model_args=registered_model_args,
    prediction_environment=prediction_environment,
    deployment_args=deployment_args,
)

app_runtime_parameters = [
    datarobot.ApplicationSourceRuntimeParameterValueArgs(
        key={{llm_app_name}}_application_name.upper() + "_DEPLOYMENT_ID",
        type="string",
        value=llm_deployment.id,
    ),
    datarobot.ApplicationSourceRuntimeParameterValueArgs(
        key="USE_DATAROBOT_LLM_GATEWAY",
        type="string",
        value="1",
    ),
    datarobot.ApplicationSourceRuntimeParameterValueArgs(
        key={{llm_app_name}}_application_name.upper() + "_DEFAULT_MODEL",
        type="string",
        value=default_model,
    ),
]
custom_model_runtime_parameters = [
    datarobot.CustomModelRuntimeParameterValueArgs(
        key="LLM_DEPLOYMENT_ID",
        type="string",
        value=llm_deployment.id,
    ),
    datarobot.CustomModelRuntimeParameterValueArgs(
        key={{llm_app_name}}_application_name.upper() + "_DEFAULT_MODEL",
        type="string",
        value=default_model,
    ),
]
pulumi.export("Deployment ID " + {{llm_app_name}}_resource_name, llm_deployment.id)
export("LLM_DEPLOYMENT_ID", llm_deployment.id)
export("USE_DATAROBOT_LLM_GATEWAY", "1")
export("{{llm_app_name|upper}}_DEFAULT_MODEL", default_model)
