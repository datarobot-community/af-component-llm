# Copyright 2025 DataRobot, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
This LLM configuration option is useful when you already have an LLM Deployed.
It will pull it into the playground and use case. It isn't sufficient if you
have a registered model you would like added to an LLM Blueprint and deployed.
For that, you'll need to choose the "registered_model_llm.py" option
"""

import os
import datarobot as dr
from datarobot_pulumi_utils.pulumi.custom_model_deployment import (
    CustomModelDeployment,
    DeploymentArgs,
    RegisteredModelArgs,
)
from datarobot_pulumi_utils.pulumi import export
from datarobot_pulumi_utils.pulumi.proxy_llm_blueprint import ProxyLLMBlueprint
from datarobot_pulumi_utils.pulumi.stack import PROJECT_NAME
from datarobot_pulumi_utils.schema.custom_models import CustomModelArgs
from datarobot_pulumi_utils.schema.exec_envs import RuntimeEnvironments
from datarobot_pulumi_utils.schema.llms import LLMSettings
import pulumi
import pulumi_datarobot as datarobot

from . import use_case
from .lib{{ llm_app_name|lower|replace('-','_')}} import (
    validate_feature_flags,
    verify_llm,
)

__all__ = [
    "custom_model_runtime_parameters",
    "app_runtime_parameters",
    "default_model",
    "{{llm_app_name}}_application_name",
    "{{llm_app_name}}_resource_name",
]

REQUIRED_FEATURE_FLAGS = {
    "ENABLE_MLOPS": True,
    "ENABLE_CUSTOM_INFERENCE_MODEL": True,
    "ENABLE_PUBLIC_NETWORK_ACCESS_FOR_ALL_CUSTOM_MODELS": True,
    "ENABLE_MLOPS_TEXT_GENERATION_TARGET_TYPE": True,
}

TEXTGEN_REGISTERED_MODEL_ID = os.environ["TEXTGEN_REGISTERED_MODEL_ID"]

{{llm_app_name}}_application_name: str = "{{llm_app_name}}"
{{llm_app_name}}_resource_name: str = "[{{llm_app_name}}]"
default_model: str = "datarobot-deployed-llm"

# Verify the feature flags are available
validate_feature_flags(REQUIRED_FEATURE_FLAGS)

playground = datarobot.Playground(
    use_case_id=use_case.id,
    resource_name=f"LLM Playground [{PROJECT_NAME}]" + {{llm_app_name}}_resource_name,
)

registered_model_args = RegisteredModelArgs(
    resource_name="LLM Registered Model " + {{llm_app_name}}_resource_name,
)

prediction_environment = datarobot.PredictionEnvironment(
    resource_name="LLM Prediction Environment " + {{llm_app_name}}_resource_name,
    platform=dr.enums.PredictionEnvironmentPlatform.DATAROBOT_SERVERLESS,
)

# Pull in the registered model
proxy_llm_registered_model = datarobot.RegisteredModel.get(
    resource_name="Existing TextGen Registered Model",
    id=TEXTGEN_REGISTERED_MODEL_ID,
)

# Create the deployment for that registered model
proxy_llm_deployment = datarobot.Deployment(
    resource_name=f"LLM Deployment [{PROJECT_NAME}]",
    registered_model_version_id=proxy_llm_registered_model.version_id,
    prediction_environment_id=prediction_environment.id,
    label=f"Data Analyst LLM Deployment [{PROJECT_NAME}]",
    use_case_ids=[use_case.id],
    opts=pulumi.ResourceOptions(replace_on_changes=["registered_model_version_id"]),
)

# Use Pulumi apply to verify the registered model LLM once deployed
proxy_llm_deployment.id.apply(lambda id: verify_llm(deployment_id=id))

# Make a LLM Blueprint from the deployed registered model
proxy_llm_validation = datarobot.CustomModelLlmValidation(
    resource_name="LLM Blueprint Validation " + {{llm_app_name}}_resource_name,
    chat_model_id=default_model,
    deployment_id=proxy_llm_deployment.id,
    use_case_id=use_case.id,
)
llm_blueprint = datarobot.LlmBlueprint(
    resource_name="LLM Blueprint " + {{llm_app_name}}_resource_name,
    custom_model_llm_settings=datarobot.LlmBlueprintCustomModelLlmSettingsArgs(
        validation_id=proxy_llm_validation.id,
    ),
    llm_id="custom-model",
    playground_id=playground.id,
)

custom_model_args = CustomModelArgs(
    resource_name="LLM Custom Model " + {{llm_app_name}}_resource_name,
    name="LLM Custom Model " + {{llm_app_name}}_resource_name,
    target_name="resultText",
    target_type=dr.enums.TARGET_TYPE.TEXT_GENERATION,
    replicas=1,
    base_environment_id=RuntimeEnvironments.PYTHON_312_MODERATIONS.value.id,
)

deployment_args = DeploymentArgs(
    resource_name="LLM Deployment Args " + {{llm_app_name}}_resource_name,
    label=f"LLM Deployment [{PROJECT_NAME}] " + {{llm_app_name}}_resource_name,
    association_id_settings=datarobot.DeploymentAssociationIdSettingsArgs(
        column_names=["association_id"],
        auto_generate_id=False,
        required_in_prediction_requests=True,
    ),
    predictions_data_collection_settings=datarobot.DeploymentPredictionsDataCollectionSettingsArgs(
        enabled=True,
    ),
    predictions_settings=(
        datarobot.DeploymentPredictionsSettingsArgs(min_computes=0, max_computes=2)
    ),
)

llm_custom_model = datarobot.CustomModel(
    **custom_model_args.model_dump(exclude_none=True),
    use_case_ids=[use_case.id],
    source_llm_blueprint_id=llm_blueprint.id,
    runtime_parameter_values=[],
)

llm_deployment = CustomModelDeployment(
    resource_name="LLM Blueprint Deployment " + {{llm_app_name}}_resource_name,
    use_case_ids=[use_case.id],
    custom_model_version_id=llm_custom_model.version_id,
    registered_model_args=registered_model_args,
    prediction_environment=prediction_environment,
    deployment_args=deployment_args,
)


app_runtime_parameters = [
    datarobot.ApplicationSourceRuntimeParameterValueArgs(
        key={{llm_app_name}}_application_name.upper() + "_DEPLOYMENT_ID",
        type="string",
        value=llm_deployment.id,
    ),
    datarobot.ApplicationSourceRuntimeParameterValueArgs(
        key={{llm_app_name}}_application_name.upper() + "_DEFAULT_MODEL",
        type="string",
        value=default_model,
    ),
    datarobot.ApplicationSourceRuntimeParameterValueArgs(
        key={{llm_app_name}}_application_name.upper() + "_DEFAULT_MODEL_FRIENDLY_NAME",
        type="string",
        value=proxy_llm_registered_model.name,
    ),
]
custom_model_runtime_parameters = [
    datarobot.CustomModelRuntimeParameterValueArgs(
        key="LLM_DEPLOYMENT_ID",
        type="string",
        value=proxy_llm_deployment.id,
    ),
    datarobot.CustomModelRuntimeParameterValueArgs(
        key={{llm_app_name}}_application_name.upper() + "_DEFAULT_MODEL",
        type="string",
        value=default_model,
    ),
]

pulumi.export("Deployment ID " + {{llm_app_name}}_resource_name, proxy_llm_deployment.id)
export("LLM_DEPLOYMENT_ID", proxy_llm_deployment.id)
export("{{llm_app_name|upper}}_DEFAULT_MODEL", default_model)
export("{{llm_app_name|upper}}_DEFAULT_MODEL_FRIENDLY_NAME", proxy_llm_registered_model.name)
